{"cells":[{"cell_type":"markdown","id":"b8062039","metadata":{"id":"b8062039"},"source":["## Regression"]},{"cell_type":"code","execution_count":null,"id":"37653077","metadata":{"id":"37653077"},"outputs":[],"source":["## Linear Regression (simple & Multi Linear)\n","Linear regression model assumes that the relationship between the dependent variable y and the\n","regressors x is linear. Linear regression models are often fitted using the least squares approach.\n","\n","y = B0 + B1X1 + ...+ E"]},{"cell_type":"code","execution_count":null,"id":"15c5b2b0","metadata":{"id":"15c5b2b0"},"outputs":[],"source":["## Polynomial Regression\n","Polynomial Regression is a form of Linear regression known as a special case of Multiple linear regression which estimates\n","the relationship as an nth degree polynomial.\n","\n","instaed of linear has square of the x coiefecient.\n","y = B0 + B1X1^2 + B2X2^2...+ E"]},{"cell_type":"code","execution_count":null,"id":"4a11ab4f","metadata":{"id":"4a11ab4f"},"outputs":[],"source":["## Support Vector Regression\n","SVR gives us the flexibility to define how much error is acceptable in our model and will find an appropriate line\n","(or hyperplane in higher dimensions) to fit the data.\n","\n","pipe of error is ignored."]},{"cell_type":"code","execution_count":null,"id":"338f6693","metadata":{"id":"338f6693"},"outputs":[],"source":["## Logistic Regression\n","Logistic Regression is often used for classification and predictive analytics. Logistic regression estimates the probability\n","of an event occurring\n","\n","Logit(pi) = 1/(1+ exp(-pi))\n","ln(pi/(1-pi)) = B0 + B1X1 + ...+ E"]},{"cell_type":"code","execution_count":null,"id":"be57ebf6","metadata":{"id":"be57ebf6"},"outputs":[],"source":["## Decision Trees\n"," non-parametric supervised learning method used for classification and regression. The goal is to create a model\n","that predicts the value of a target variable by learning simple decision rules inferred from the data features"]},{"cell_type":"code","source":[],"metadata":{"id":"fgyEPqLX0oQ7"},"id":"fgyEPqLX0oQ7","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"1acd0713","metadata":{"id":"1acd0713"},"outputs":[],"source":["## Random Forest\n","Random Forest trains a fixed amount of Decision Trees and (normally) averages the results from all those previous models\n","and just like Decision Trees, we have Classification and Regression Random Forests\n","\n","A Random Forest is a collection of decision trees, each trained independently on a random subset of the training dataset\n"," (sampled with replacement). The algorithm is unique in that it is robust to overfitting, and easy to use."]},{"cell_type":"markdown","id":"8899fe02","metadata":{"id":"8899fe02"},"source":["## Classification"]},{"cell_type":"code","execution_count":null,"id":"ff0446e7","metadata":{"id":"ff0446e7"},"outputs":[],"source":["Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"8f72a030","metadata":{"id":"8f72a030"},"outputs":[],"source":["K Nearest Neighobour (K-NN)"]},{"cell_type":"code","execution_count":null,"id":"1851f428","metadata":{"id":"1851f428"},"outputs":[],"source":["Support Vector Machine (SVM)"]},{"cell_type":"code","execution_count":null,"id":"ab02820f","metadata":{"id":"ab02820f"},"outputs":[],"source":["Kernel SVM"]},{"cell_type":"code","execution_count":null,"id":"e99deffc","metadata":{"id":"e99deffc"},"outputs":[],"source":["Naive Bayes"]},{"cell_type":"code","execution_count":null,"id":"0b29a9de","metadata":{"id":"0b29a9de"},"outputs":[],"source":["Decession tree"]},{"cell_type":"code","execution_count":null,"id":"d956ff14","metadata":{"id":"d956ff14"},"outputs":[],"source":["Random Forest"]},{"cell_type":"markdown","id":"93271705","metadata":{"id":"93271705"},"source":["## Clustering"]},{"cell_type":"code","execution_count":null,"id":"e4b55f7a","metadata":{"id":"e4b55f7a"},"outputs":[],"source":["K Means"]},{"cell_type":"code","execution_count":null,"id":"c0caaef1","metadata":{"id":"c0caaef1"},"outputs":[],"source":["Heirarchial"]},{"cell_type":"markdown","source":["## Others"],"metadata":{"id":"4wNX3qcddI0n"},"id":"4wNX3qcddI0n"},{"cell_type":"code","source":["Association Rule Learning - Apriori"],"metadata":{"id":"mCGz84DydWpH"},"id":"mCGz84DydWpH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Association Rule Learning - Eclat"],"metadata":{"id":"JpX7HZuydchO"},"id":"JpX7HZuydchO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Natural language Processing"],"metadata":{"id":"mPXtGWXLeAVN"},"id":"mPXtGWXLeAVN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Deep Learning - Artificial Neural Network (ANN) - TensorFlow"],"metadata":{"id":"gaOQ7VwieHvR"},"id":"gaOQ7VwieHvR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Convolution Neural Network (CNN)"],"metadata":{"id":"vM1ExJEUedoZ"},"id":"vM1ExJEUedoZ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}